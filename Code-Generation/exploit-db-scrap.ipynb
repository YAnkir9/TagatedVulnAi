{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Scrapping entire data from the Exploits-db site (If it failed in between increase the driver wait time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error setting entries per page: Message: \n",
      "\n",
      "Scraping page 1 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:13<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 2 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:21<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 3 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:16<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 4 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:20<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 5 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:18<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 6 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:22<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 7 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:17<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 8 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:16<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 9 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:17<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 10 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:21<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 11 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:22<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 12 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:23<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 13 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:26<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 14 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:32<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 15 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:18<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 16 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:17<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 17 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:23<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 18 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:15<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 19 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:21<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 20 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:23<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 21 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:18<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 22 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:15<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 23 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:47<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 24 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 25 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 26 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:20<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 27 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:26<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 28 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:20<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 29 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:15<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 30 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:17<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 31 at https://www.exploit-db.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Exploits: 100%|██████████| 120/120 [01:23<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1: Error clicking next page: Message: \n",
      "Stacktrace:\n",
      "#0 0x58ec823e2a5a <unknown>\n",
      "#1 0x58ec81ef02f0 <unknown>\n",
      "#2 0x58ec81f3f235 <unknown>\n",
      "#3 0x58ec81f3f451 <unknown>\n",
      "#4 0x58ec81f84dc4 <unknown>\n",
      "#5 0x58ec81f63bed <unknown>\n",
      "#6 0x58ec81f8211e <unknown>\n",
      "#7 0x58ec81f63963 <unknown>\n",
      "#8 0x58ec81f30eec <unknown>\n",
      "#9 0x58ec81f3213e <unknown>\n",
      "#10 0x58ec823af1cf <unknown>\n",
      "#11 0x58ec823b32dd <unknown>\n",
      "#12 0x58ec8239d6d7 <unknown>\n",
      "#13 0x58ec823b3a51 <unknown>\n",
      "#14 0x58ec82384d1e <unknown>\n",
      "#15 0x58ec823d1538 <unknown>\n",
      "#16 0x58ec823d173a <unknown>\n",
      "#17 0x58ec823e16cc <unknown>\n",
      "#18 0x7982a73f7ac3 <unknown>\n",
      "\n",
      "Attempt 2: Error clicking next page: Message: \n",
      "Stacktrace:\n",
      "#0 0x58ec823e2a5a <unknown>\n",
      "#1 0x58ec81ef02f0 <unknown>\n",
      "#2 0x58ec81f3f235 <unknown>\n",
      "#3 0x58ec81f3f451 <unknown>\n",
      "#4 0x58ec81f84dc4 <unknown>\n",
      "#5 0x58ec81f63bed <unknown>\n",
      "#6 0x58ec81f8211e <unknown>\n",
      "#7 0x58ec81f63963 <unknown>\n",
      "#8 0x58ec81f30eec <unknown>\n",
      "#9 0x58ec81f3213e <unknown>\n",
      "#10 0x58ec823af1cf <unknown>\n",
      "#11 0x58ec823b32dd <unknown>\n",
      "#12 0x58ec8239d6d7 <unknown>\n",
      "#13 0x58ec823b3a51 <unknown>\n",
      "#14 0x58ec82384d1e <unknown>\n",
      "#15 0x58ec823d1538 <unknown>\n",
      "#16 0x58ec823d173a <unknown>\n",
      "#17 0x58ec823e16cc <unknown>\n",
      "#18 0x7982a73f7ac3 <unknown>\n",
      "\n",
      "Attempt 3: Error clicking next page: Message: \n",
      "Stacktrace:\n",
      "#0 0x58ec823e2a5a <unknown>\n",
      "#1 0x58ec81ef02f0 <unknown>\n",
      "#2 0x58ec81f3f235 <unknown>\n",
      "#3 0x58ec81f3f451 <unknown>\n",
      "#4 0x58ec81f84dc4 <unknown>\n",
      "#5 0x58ec81f63bed <unknown>\n",
      "#6 0x58ec81f8211e <unknown>\n",
      "#7 0x58ec81f63963 <unknown>\n",
      "#8 0x58ec81f30eec <unknown>\n",
      "#9 0x58ec81f3213e <unknown>\n",
      "#10 0x58ec823af1cf <unknown>\n",
      "#11 0x58ec823b32dd <unknown>\n",
      "#12 0x58ec8239d6d7 <unknown>\n",
      "#13 0x58ec823b3a51 <unknown>\n",
      "#14 0x58ec82384d1e <unknown>\n",
      "#15 0x58ec823d1538 <unknown>\n",
      "#16 0x58ec823d173a <unknown>\n",
      "#17 0x58ec823e16cc <unknown>\n",
      "#18 0x7982a73f7ac3 <unknown>\n",
      "\n",
      "Scraping completed. Data saved to exploits.csv.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Setup Chrome options\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Function to fetch and parse the page content with retries\n",
    "def fetch_page(retries=3, delay=2):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            return BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1}: Error fetching page content: {e}\")\n",
    "            time.sleep(delay)\n",
    "    return None\n",
    "\n",
    "# Function to scrape the main list of exploits\n",
    "def scrape_exploit_list():\n",
    "    soup = fetch_page()\n",
    "    if not soup:\n",
    "        return []\n",
    "\n",
    "    exploit_data = []\n",
    "    table = soup.find('table', {'id': 'exploits-table'})\n",
    "    if table:\n",
    "        rows = table.find_all('tr')[1:]  # Skip header row\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                date = cols[0].text.strip() if cols[0] else 'N/A'\n",
    "                exploit_link = cols[1].find('a', href=True)['href'] if cols[1].find('a', href=True) else 'N/A'\n",
    "                description = cols[4].find('a').text.strip() if cols[4].find('a') else 'N/A'\n",
    "                category = cols[5].find('a').text.strip() if cols[5].find('a') else 'N/A'\n",
    "                platform = cols[6].find('a').text.strip() if cols[6].find('a') else 'N/A'\n",
    "                author = cols[7].find('a').text.strip() if cols[7].find('a') else 'N/A'\n",
    "                \n",
    "                if exploit_link and exploit_link != 'N/A':\n",
    "                    exploit_link = f\"https://www.exploit-db.com{exploit_link}\"\n",
    "\n",
    "                exploit_data.append({\n",
    "                    'date': date,\n",
    "                    'exploit_link': exploit_link,\n",
    "                    'description': description,\n",
    "                    'category': category,\n",
    "                    'platform': platform,\n",
    "                    'author': author\n",
    "                })\n",
    "    return exploit_data\n",
    "\n",
    "# Function to scrape details of each exploit\n",
    "def scrape_exploit_details(exploit_link):\n",
    "    try:\n",
    "        driver.get(exploit_link)\n",
    "        soup = fetch_page()\n",
    "        if not soup:\n",
    "            return {}\n",
    "        \n",
    "        title = soup.find('h1').text.strip() if soup.find('h1') else 'N/A'\n",
    "        platform_detail = soup.find('div', class_='platform').text.strip() if soup.find('div', class_='platform') else 'N/A'\n",
    "        \n",
    "        return {\n",
    "            'exploit_link': exploit_link,\n",
    "            'title': title,\n",
    "            'platform_detail': platform_detail\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {exploit_link}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Function to click the next page button with retries\n",
    "def click_next_page(retries=3, delay=2):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            next_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//li[@class=\"paginate_button page-item next\"]/a'))\n",
    "            )\n",
    "            next_button.click()\n",
    "            WebDriverWait(driver, 10).until(EC.staleness_of(next_button))\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1}: Error clicking next page: {e}\")\n",
    "            time.sleep(delay)\n",
    "    return False\n",
    "\n",
    "def set_entries_per_page():\n",
    "    try:\n",
    "        select_element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.NAME, 'exploits-table_length'))\n",
    "        )\n",
    "        select = Select(select_element)\n",
    "        select.select_by_value('120')\n",
    "        WebDriverWait(driver, 10).until(EC.staleness_of(select_element))\n",
    "        print(\"Set entries per page to 120.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting entries per page: {e}\")\n",
    "\n",
    "# Main scraping loop with visualization\n",
    "def main():\n",
    "    base_url = 'https://www.exploit-db.com'\n",
    "    driver.get(base_url)\n",
    "\n",
    "    set_entries_per_page()\n",
    "\n",
    "    with open('exploits1.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "        fieldnames = ['date', 'exploit_link', 'description', 'category', 'platform', 'author', 'title', 'platform_detail']\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        page_number = 1\n",
    "        while True:\n",
    "            print(f'Scraping page {page_number} at {driver.current_url}')\n",
    "            exploit_links = scrape_exploit_list()\n",
    "\n",
    "            valid_links = [link['exploit_link'] for link in exploit_links if link['exploit_link'] and link['exploit_link'] != 'N/A']\n",
    "\n",
    "            if not valid_links:\n",
    "                print(\"No valid exploit links found on this page.\")\n",
    "                continue\n",
    "\n",
    "            with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "                results = list(tqdm(executor.map(scrape_exploit_details, valid_links), total=len(valid_links), desc=\"Scraping Exploits\"))\n",
    "\n",
    "            for exploit in exploit_links:\n",
    "                details = next((item for item in results if item['exploit_link'] == exploit['exploit_link']), {})\n",
    "                if details:\n",
    "                    exploit.update(details)\n",
    "                    writer.writerow(exploit)\n",
    "\n",
    "            if not click_next_page():\n",
    "                break\n",
    "\n",
    "            page_number += 1\n",
    "\n",
    "    print('Scraping completed. Data saved to exploits.csv.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMCVEs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
